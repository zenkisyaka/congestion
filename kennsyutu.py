import os
from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt

# 1ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆYOLOv8 ã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼‰
model_path = "/Users/chinenyoshinori/congestion-1/runs/detect/train16/weights/best.pt"
model = YOLO(model_path)

# 2ï¸âƒ£ ç”»åƒã®èª­ã¿è¾¼ã¿
image_path = "/Users/chinenyoshinori/congestion-1/data/add.images/image_51.jpg"
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # OpenCV ã® BGR å½¢å¼ã‚’ RGB ã«å¤‰æ›
height, width, _ = image.shape

# 3ï¸âƒ£ ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆï¼ˆãªã‘ã‚Œã°ä½œã‚‹ï¼‰
save_dir = "/Users/chinenyoshinori/congestion-1/yolo_results"
os.makedirs(save_dir, exist_ok=True)  # ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°ä½œæˆ

# 4ï¸âƒ£ YOLO ã§ç‰©ä½“æ¤œå‡º
results = model(image)

# 5ï¸âƒ£ æ¤œå‡ºçµæœã‚’ãƒªã‚¹ãƒˆåŒ–ï¼ˆãƒ†ã‚­ã‚¹ãƒˆä¿å­˜ç”¨ï¼‰
detections = []

# 6ï¸âƒ£ æ¤œå‡ºçµæœã‚’ç”»åƒã«æç”»
for result in results:
    for box in result.boxes:
        x1, y1, x2, y2 = map(int, box.xyxy[0])  # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®åº§æ¨™ (å·¦ä¸Š, å³ä¸‹)
        conf = float(box.conf[0])  # ä¿¡é ¼åº¦ï¼ˆConfidence Scoreï¼‰
        cls = int(box.cls[0])  # ã‚¯ãƒ©ã‚¹ID
        class_name = model.names[cls]  # ã‚¯ãƒ©ã‚¹åï¼ˆãƒ©ãƒ™ãƒ«ï¼‰

        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®æç”»ï¼ˆèµ¤æ ï¼‰
        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)
        label = f"{class_name}: {conf:.2f}"
        cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

        # æ¤œå‡ºçµæœã‚’ãƒªã‚¹ãƒˆã«ä¿å­˜
        detections.append(f"{class_name} {conf:.2f} {x1} {y1} {x2} {y2}")

# 7ï¸âƒ£ æ¤œå‡ºçµæœã‚’ TXT ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
txt_output_path = os.path.join(save_dir, "yolo_predictions.txt")
with open(txt_output_path, "w") as f:
    for detection in detections:
        f.write(detection + "\n")
print(f"ğŸ“„ æ¤œå‡ºçµæœã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {txt_output_path}")

# 8ï¸âƒ£ æ¤œå‡ºçµæœã‚’ç”»åƒã¨ã—ã¦ä¿å­˜
output_image_path = os.path.join(save_dir, "yolo_prediction.jpg")
cv2.imwrite(output_image_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
print(f"ğŸ“· æ¤œå‡ºçµæœã®ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_image_path}")

# 9ï¸âƒ£ ç”»åƒã‚’è¡¨ç¤º
plt.figure(figsize=(10, 6))
plt.imshow(image)
plt.axis("off")
plt.show()


import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
image_path = "/Users/chinenyoshinori/congestion-1/data/add.images/image_51.jpg"
prediction_path = "/Users/chinenyoshinori/congestion-1/yolo_results/yolo_predictions.txt"
annotation_path = "/Users/chinenyoshinori/congestion-1/ano_51-60/image_51.txt"

# ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
save_dir = "/Users/chinenyoshinori/congestion-1/yolo_comparison_results"
os.makedirs(save_dir, exist_ok=True)

# ç”»åƒã‚’èª­ã¿è¾¼ã‚€
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
height, width, _ = image.shape

# YOLO ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆæ­£è¦åŒ–ã•ã‚ŒãŸåº§æ¨™ï¼‰ã‚’ (x1, y1, x2, y2) ã«å¤‰æ›
def yolo_to_bbox(yolo_bbox, img_width, img_height):
    x_center, y_center, w, h = yolo_bbox
    x1 = int((x_center - w / 2) * img_width)
    y1 = int((y_center - h / 2) * img_height)
    x2 = int((x_center + w / 2) * img_width)
    y2 = int((y_center + h / 2) * img_height)
    return x1, y1, x2, y2

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
def load_bboxes(file_path):
    bboxes = []
    if not os.path.exists(file_path):
        print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return bboxes  # ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™

    with open(file_path, "r") as f:
        for line in f:
            values = list(map(float, line.strip().split()))
            if len(values) == 6:  # YOLO ã®æ¤œå‡ºçµæœ
                class_id, x, y, w, h, conf = values
            else:  # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
                class_id, x, y, w, h = values
                conf = 1.0  # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä¿¡é ¼åº¦ 1.0

            bbox = yolo_to_bbox((x, y, w, h), width, height)
            bboxes.append((class_id, bbox, conf))
    return bboxes

# IoUï¼ˆIntersection over Unionï¼‰ã®è¨ˆç®—
def compute_iou(box1, box2):
    x1, y1, x2, y2 = box1
    x1g, y1g, x2g, y2g = box2

    xi1 = max(x1, x1g)
    yi1 = max(y1, y1g)
    xi2 = min(x2, x2g)
    yi2 = min(y2, y2g)

    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)
    box1_area = (x2 - x1) * (y2 - y1)
    box2_area = (x2g - x1g) * (y2g - y1g)

    iou = inter_area / (box1_area + box2_area - inter_area)
    return iou, (xi1, yi1, xi2, yi2)  # Intersection ã®åº§æ¨™ã‚‚è¿”ã™

# ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿
predictions = load_bboxes(prediction_path)
annotations = load_bboxes(annotation_path)

# æ¤œå‡ºçµæœã‚’ãƒªã‚¹ãƒˆåŒ–ï¼ˆIoU ä¿å­˜ç”¨ï¼‰
iou_results = []

# æ¤œå‡ºçµæœã‚’æç”»
for _, pred_box, conf in predictions:
    x1, y1, x2, y2 = pred_box
    cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)  # é’è‰²
    cv2.putText(image, f"Pred {conf:.2f}", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

# ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æç”»
for _, gt_box, _ in annotations:
    x1, y1, x2, y2 = gt_box
    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # ç·‘è‰²
    cv2.putText(image, "GT", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

# å„äºˆæ¸¬ã«å¯¾ã™ã‚‹ IoU ã‚’è¨ˆç®—ã—ã¦è¡¨ç¤º
for _, pred_box, _ in predictions:
    best_iou = 0
    best_intersection = None
    for _, gt_box, _ in annotations:
        iou, intersection = compute_iou(pred_box, gt_box)
        if iou > best_iou:
            best_iou = iou
            best_intersection = intersection

    x1, y1, _, _ = pred_box
    cv2.putText(image, f"IoU: {best_iou:.2f}", (x1, y1 + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

    # IoU ã®é‡ãªã‚Šã‚’åŠé€æ˜ã®å¡—ã‚Šã¤ã¶ã—ã§è¡¨ç¤º
    if best_intersection is not None:
        xi1, yi1, xi2, yi2 = best_intersection
        overlay = image.copy()
        alpha = best_iou * 0.7  # IoU ãŒé«˜ã„ã»ã©æ¿ƒããªã‚‹
        cv2.rectangle(overlay, (xi1, yi1), (xi2, yi2), (255, 255, 0), -1)  # é»„è‰²
        cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)
        cv2.putText(image, "Overlap", (xi1, yi1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

# IoU ã®çµæœã‚’ TXT ã«ä¿å­˜
iou_txt_path = os.path.join(save_dir, "iou_results.txt")
with open(iou_txt_path, "w") as f:
    for line in iou_results:
        f.write(line + "\n")
print(f"ğŸ“„ IoU ã®çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {iou_txt_path}")

# çµæœã‚’ä¿å­˜
output_image_path = os.path.join(save_dir, "bbox_comparison_with_overlap.jpg")
cv2.imwrite(output_image_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
print(f"ğŸ“· æ¤œå‡ºçµæœã®ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_image_path}")

# çµæœã‚’è¡¨ç¤º
plt.figure(figsize=(10, 6))
plt.imshow(image)
plt.axis("off")
plt.show()
